Сталкирующая модель кажется хорошей для мультиагентных систем. Нужно получше разобрать приемущества сталкирующей модели.
Не так много людей думают в сторону ограничения модели чтобы получить специфику. Однако у человека это работает именно через ограничение(забывание) + наложение цели + обучение новой информации. Важно чтобы при этом модель не теряла способность рассуждать и не теряла базовый способ коммуникации.


Цель, вероятно, должна быть заложена в обучение модели изначально(либо в файн-тюнинг), чтобы модель могла сверять данные и предназночение модели. Чтобы она училась в конкретной узкой области. Вероятно это лучше, чем урезать и обрезать модели. 
Она должна сама себя натренировать концентрировать свои веса на цели и на задаче одновременно. Возможно здесь имеет место новый алгоритм посика ошибки. Например, если модель о мире Наруто, и информация о фондовом рынке поступает в модель, то модель должна научиться сама отвечать так, чтобы не потерять соответствие цели. 
Думаю здесь есть простой подход, но следует начать со сложного.